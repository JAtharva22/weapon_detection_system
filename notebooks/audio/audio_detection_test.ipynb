{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch librosa numpy sounddevice\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g6ovIviobX8f",
        "outputId": "63a2d321-21d8-421c-e338-76c3a2b04ac0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "from torch import nn\n",
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "class MFCC_LSTM(nn.Module):\n",
        "    def __init__(self, input_size=13, hidden_size=128, num_layers=2, num_classes=8, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,      # 13 MFCC features\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def attention_net(self, lstm_output):\n",
        "        attn_weights = self.attention(lstm_output)\n",
        "        soft_attn_weights = torch.softmax(attn_weights, 1)\n",
        "        context = torch.sum(lstm_output * soft_attn_weights, 1)\n",
        "        return context\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, 13, 200)\n",
        "        # Transpose to (batch_size, 200, 13) for LSTM\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_out = self.attention_net(lstm_out)\n",
        "\n",
        "        # Fully connected layers\n",
        "        out = self.fc1(attn_out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7cKrLvepjE4i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique classes and their corresponding class IDs:\n",
        "#    classID             class\n",
        "# 0        0   air_conditioner\n",
        "# 1        1          car_horn\n",
        "# 2        2  children_playing\n",
        "# 3        3          dog_bark\n",
        "# 4        4          drilling\n",
        "# 5        5     engine_idling\n",
        "# 6        6          gun_shot\n",
        "# 7        7        jackhammer\n",
        "# 8        8             siren\n",
        "# 9        9      street_music\n",
        "\n",
        "# Audio and model parameters\n",
        "SAMPLE_RATE = 22050  # Sampling rate for MFCC extraction\n",
        "MFCC_FEATURES = 13   # Number of MFCC features\n",
        "TIME_STEPS = 200     # Number of time steps in each MFCC frame\n",
        "CHUNK_DURATION = 2.0 # Duration (in seconds) of each audio chunk to classify"
      ],
      "metadata": {
        "id": "1u8Td7m5jt-I"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, device='cpu'):\n",
        "    model = MFCC_LSTM(input_size=MFCC_FEATURES, hidden_size=128, num_layers=2, num_classes=7)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Extract MFCC features from a 4-second audio chunk\n",
        "def extract_mfcc(audio_chunk):\n",
        "    mfcc = librosa.feature.mfcc(y=audio_chunk, sr=SAMPLE_RATE, n_mfcc=MFCC_FEATURES)\n",
        "    # Pad or truncate to TIME_STEPS\n",
        "    if mfcc.shape[1] < TIME_STEPS:\n",
        "        pad_width = ((0, 0), (0, TIME_STEPS - mfcc.shape[1]))\n",
        "        mfcc = np.pad(mfcc, pad_width, mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:, :TIME_STEPS]\n",
        "    return mfcc\n",
        "\n",
        "# Perform prediction on a single 4-second audio segment\n",
        "def detect_audio_segment(audio_segment, model, device='cpu'):\n",
        "    mfcc_features = extract_mfcc(audio_segment)\n",
        "    features_tensor = torch.FloatTensor(mfcc_features).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(features_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        predicted_class = torch.argmax(outputs, dim=1).item()\n",
        "        confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "    label_map = {0: 0, 1: 2, 2: 3, 3: 4, 4: 6, 5: 8, 6: 9}\n",
        "    label_map = {\n",
        "        0: 'air_conditioner',\n",
        "        1: 'children_playing',\n",
        "        2: 'dog_bark',\n",
        "        3: 'drilling',\n",
        "        4: 'gun_shot',\n",
        "        5: 'siren',\n",
        "        6: 'street_music'\n",
        "    }\n",
        "    original_label = label_map[predicted_class]\n",
        "    return original_label, confidence\n",
        "\n",
        "# Process the audio file in 4-second chunks\n",
        "def process_audio_file_in_chunks(audio_path, model, device='cpu'):\n",
        "    chunk_samples = int(CHUNK_DURATION * SAMPLE_RATE)\n",
        "\n",
        "    # Load only the needed part of the audio each time\n",
        "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "    num_chunks = len(y) // chunk_samples\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_samples\n",
        "        end = start + chunk_samples\n",
        "        audio_chunk = y[start:end]\n",
        "\n",
        "        # Classify this 4-second chunk\n",
        "        label, confidence = detect_audio_segment(audio_chunk, model, device)\n",
        "        print(f\"Chunk {i+1}: Detected Class = {label}, Confidence = {confidence:.2%}\")\n"
      ],
      "metadata": {
        "id": "-WPX2EewgLNQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load model and start processing\n",
        "model_path = '/content/best_model.pth'  # Replace with your actual model path\n",
        "audio_path = '/content/gun_asmr.wav'  # Replace with your actual audio file path\n",
        "device = 'cpu'  # Change to 'cuda' if using GPU\n",
        "\n",
        "model = load_model(model_path, device)\n",
        "process_audio_file_in_chunks(audio_path, model, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_2bZdq5BidW2",
        "outputId": "42998f06-e480-4fc4-a6b0-793566c78abc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ecc44a2f5ae3>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Detected Class = gun_shot, Confidence = 99.83%\n",
            "Chunk 2: Detected Class = dog_bark, Confidence = 98.84%\n",
            "Chunk 3: Detected Class = gun_shot, Confidence = 49.77%\n",
            "Chunk 4: Detected Class = gun_shot, Confidence = 99.51%\n",
            "Chunk 5: Detected Class = drilling, Confidence = 68.18%\n",
            "Chunk 6: Detected Class = drilling, Confidence = 41.38%\n",
            "Chunk 7: Detected Class = gun_shot, Confidence = 83.25%\n",
            "Chunk 8: Detected Class = gun_shot, Confidence = 94.98%\n",
            "Chunk 9: Detected Class = gun_shot, Confidence = 98.29%\n",
            "Chunk 10: Detected Class = dog_bark, Confidence = 69.88%\n",
            "Chunk 11: Detected Class = gun_shot, Confidence = 61.14%\n",
            "Chunk 12: Detected Class = dog_bark, Confidence = 70.94%\n",
            "Chunk 13: Detected Class = street_music, Confidence = 92.30%\n",
            "Chunk 14: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 15: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 16: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 17: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 18: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 19: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 20: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 21: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 22: Detected Class = gun_shot, Confidence = 99.93%\n",
            "Chunk 23: Detected Class = gun_shot, Confidence = 93.06%\n",
            "Chunk 24: Detected Class = gun_shot, Confidence = 99.57%\n",
            "Chunk 25: Detected Class = dog_bark, Confidence = 53.49%\n",
            "Chunk 26: Detected Class = gun_shot, Confidence = 99.47%\n",
            "Chunk 27: Detected Class = gun_shot, Confidence = 91.42%\n",
            "Chunk 28: Detected Class = gun_shot, Confidence = 99.84%\n",
            "Chunk 29: Detected Class = dog_bark, Confidence = 64.08%\n",
            "Chunk 30: Detected Class = gun_shot, Confidence = 70.45%\n",
            "Chunk 31: Detected Class = dog_bark, Confidence = 98.24%\n",
            "Chunk 32: Detected Class = gun_shot, Confidence = 99.47%\n",
            "Chunk 33: Detected Class = gun_shot, Confidence = 97.94%\n",
            "Chunk 34: Detected Class = gun_shot, Confidence = 94.40%\n",
            "Chunk 35: Detected Class = gun_shot, Confidence = 99.74%\n",
            "Chunk 36: Detected Class = gun_shot, Confidence = 92.59%\n",
            "Chunk 37: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 38: Detected Class = dog_bark, Confidence = 99.82%\n",
            "Chunk 39: Detected Class = street_music, Confidence = 89.38%\n",
            "Chunk 40: Detected Class = dog_bark, Confidence = 47.44%\n",
            "Chunk 41: Detected Class = dog_bark, Confidence = 81.77%\n",
            "Chunk 42: Detected Class = street_music, Confidence = 41.61%\n",
            "Chunk 43: Detected Class = street_music, Confidence = 95.13%\n",
            "Chunk 44: Detected Class = street_music, Confidence = 96.71%\n",
            "Chunk 45: Detected Class = street_music, Confidence = 56.49%\n",
            "Chunk 46: Detected Class = gun_shot, Confidence = 99.83%\n",
            "Chunk 47: Detected Class = gun_shot, Confidence = 99.58%\n",
            "Chunk 48: Detected Class = street_music, Confidence = 72.32%\n",
            "Chunk 49: Detected Class = dog_bark, Confidence = 59.06%\n",
            "Chunk 50: Detected Class = street_music, Confidence = 60.04%\n",
            "Chunk 51: Detected Class = gun_shot, Confidence = 93.74%\n",
            "Chunk 52: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 53: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 54: Detected Class = gun_shot, Confidence = 99.44%\n",
            "Chunk 55: Detected Class = gun_shot, Confidence = 99.97%\n",
            "Chunk 56: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 57: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 58: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 59: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 60: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 61: Detected Class = gun_shot, Confidence = 99.89%\n",
            "Chunk 62: Detected Class = gun_shot, Confidence = 99.95%\n",
            "Chunk 63: Detected Class = drilling, Confidence = 93.88%\n",
            "Chunk 64: Detected Class = gun_shot, Confidence = 99.73%\n",
            "Chunk 65: Detected Class = drilling, Confidence = 66.32%\n",
            "Chunk 66: Detected Class = gun_shot, Confidence = 94.57%\n",
            "Chunk 67: Detected Class = gun_shot, Confidence = 97.59%\n",
            "Chunk 68: Detected Class = gun_shot, Confidence = 99.68%\n",
            "Chunk 69: Detected Class = gun_shot, Confidence = 99.73%\n",
            "Chunk 70: Detected Class = gun_shot, Confidence = 96.16%\n",
            "Chunk 71: Detected Class = drilling, Confidence = 56.81%\n",
            "Chunk 72: Detected Class = gun_shot, Confidence = 97.59%\n",
            "Chunk 73: Detected Class = dog_bark, Confidence = 68.58%\n",
            "Chunk 74: Detected Class = gun_shot, Confidence = 99.82%\n",
            "Chunk 75: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 76: Detected Class = gun_shot, Confidence = 99.94%\n",
            "Chunk 77: Detected Class = drilling, Confidence = 98.86%\n",
            "Chunk 78: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 79: Detected Class = gun_shot, Confidence = 99.97%\n",
            "Chunk 80: Detected Class = gun_shot, Confidence = 35.27%\n",
            "Chunk 81: Detected Class = gun_shot, Confidence = 99.48%\n",
            "Chunk 82: Detected Class = gun_shot, Confidence = 97.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import librosa\n",
        "import smtplib\n",
        "from torch import nn\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "# Model parameters\n",
        "# SAMPLE_RATE = 22050  # Sampling rate for MFCC extraction\n",
        "# MFCC_FEATURES = 13   # Number of MFCC features\n",
        "# TIME_STEPS = 200     # Number of time steps in each MFCC frame\n",
        "# CHUNK_DURATION = 2.0 # Duration (in seconds) of each audio chunk to classify\n",
        "GUNSHOT_THRESHOLD = 0.8  # Confidence threshold for detecting a gunshot sound\n",
        "live_video_link = \"http://127.0.0.1:5000/\"  # Replace with your actual video link\n",
        "\n",
        "def send_email(sender_email, receiver_email, email_password, video_link):\n",
        "    \"\"\"Send an email alert for gunshot detection with a link to CCTV footage.\"\"\"\n",
        "    msg = MIMEMultipart()\n",
        "    msg['From'] = sender_email\n",
        "    msg['To'] = receiver_email\n",
        "    msg['Subject'] = \"Gunshot Detection Alert\"\n",
        "\n",
        "    # HTML body with a clickable link\n",
        "    body = f\"\"\"\n",
        "    <html>\n",
        "        <body>\n",
        "            <p>Gunshot detected in the audio surveillance. Please check the CCTV footage.</p>\n",
        "            <p><a href=\"{live_video_link}\" target=\"_blank\">View CCTV Footage</a></p>\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "    msg.attach(MIMEText(body, 'html'))  # Set the MIME type to 'html' for rendering HTML content\n",
        "\n",
        "    # Send the email\n",
        "    try:\n",
        "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
        "            server.starttls()  # Secure the connection\n",
        "            server.login(sender_email, email_password)\n",
        "            server.send_message(msg)\n",
        "        print(\"Email alert sent successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to send email: {e}\")\n",
        "\n",
        "# Process audio file\n",
        "def process_audio_file_in_chunks_for_email(audio_path, model, device='cpu', sender_email=None, receiver_email=None, email_password=None):\n",
        "    chunk_samples = int(CHUNK_DURATION * SAMPLE_RATE)\n",
        "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "    num_chunks = len(y) // chunk_samples\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_samples\n",
        "        end = start + chunk_samples\n",
        "        audio_chunk = y[start:end]\n",
        "\n",
        "        # Classify the audio chunk\n",
        "        label, confidence = detect_audio_segment(audio_chunk, model, device)\n",
        "        print(f\"Chunk {i+1}: Detected Class = {label}, Confidence = {confidence:.2%}\")\n",
        "\n",
        "        # If gunshot is detected with high confidence, send an email\n",
        "        if label == 'gun_shot' and confidence >= GUNSHOT_THRESHOLD:\n",
        "            print(\"Gunshot detected with high confidence. Sending email alert...\")\n",
        "            send_email(sender_email, receiver_email, email_password, live_video_link)\n",
        "            break  # Stop further processing once email is sent\n",
        "\n",
        "# Usage example\n",
        "model_path = '/content/best_model.pth'  # Replace with your model path\n",
        "audio_path = '/content/gun_asmr.wav'  # Replace with your audio file path\n",
        "sender_email = \"manas.divekar76@gmail.com\"  # Replace with your email\n",
        "receiver_email = \"me.atharvajadhav@gmail.com\"  # Replace with receiver's email\n",
        "email_password = \"jemu imks maqm kaow\"  # Replace with your email password\n",
        "\n",
        "device = 'cpu'  # Change to 'cuda' if using a GPU"
      ],
      "metadata": {
        "id": "Y6M6HTs5mIvr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process audio file\n",
        "def process_audio_file_in_chunks_for_email_lmt(audio_path, model, device='cpu', sender_email=None, receiver_email=None, email_password=None):\n",
        "    chunk_samples = int(CHUNK_DURATION * SAMPLE_RATE)\n",
        "    y, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n",
        "    num_chunks = len(y) // chunk_samples\n",
        "\n",
        "    # Track gunshot detections within a rolling window of the last 6 chunks\n",
        "    recent_gunshots = [0] * 6  # A list to track gunshot detections in last 6 chunks\n",
        "    gunshot_count = 0  # Initialize gunshot counter\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_samples\n",
        "        end = start + chunk_samples\n",
        "        audio_chunk = y[start:end]\n",
        "\n",
        "        # Classify the audio chunk\n",
        "        label, confidence = detect_audio_segment(audio_chunk, model, device)\n",
        "        print(f\"Chunk {i+1}: Detected Class = {label}, Confidence = {confidence:.2%}\")\n",
        "\n",
        "        # Check if gunshot is detected with high confidence\n",
        "        if label == 'gun_shot' and confidence >= GUNSHOT_THRESHOLD:\n",
        "            recent_gunshots[i % 6] = 1  # Mark this chunk as having detected a gunshot\n",
        "        else:\n",
        "            recent_gunshots[i % 6] = 0  # Mark this chunk as not having a gunshot\n",
        "\n",
        "        # Update gunshot count based on the rolling window\n",
        "        gunshot_count = sum(recent_gunshots)\n",
        "\n",
        "        # If there are 3 gunshots in the last 6 chunks, send an email\n",
        "        if gunshot_count >= 3:\n",
        "            print(\"3 gunshots detected within the last 6 chunks. Sending email alert...\")\n",
        "            send_email(sender_email, receiver_email, email_password, live_video_link)\n",
        "            recent_gunshots = [0] * 6  # Reset recent detections after sending an email\n",
        "            gunshot_count = 0  # Reset gunshot counter"
      ],
      "metadata": {
        "id": "ZJw6K2ESmiUo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = load_model(model_path, device)\n",
        "process_audio_file_in_chunks_for_email_lmt(audio_path, model, device, sender_email, receiver_email, email_password)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3dt8koEoCDi",
        "outputId": "7a081893-a377-42a6-86e7-e3c5c0e4a013"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ecc44a2f5ae3>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: Detected Class = gun_shot, Confidence = 99.83%\n",
            "Chunk 2: Detected Class = dog_bark, Confidence = 98.84%\n",
            "Chunk 3: Detected Class = gun_shot, Confidence = 49.77%\n",
            "Chunk 4: Detected Class = gun_shot, Confidence = 99.51%\n",
            "Chunk 5: Detected Class = drilling, Confidence = 68.18%\n",
            "Chunk 6: Detected Class = drilling, Confidence = 41.38%\n",
            "Chunk 7: Detected Class = gun_shot, Confidence = 83.25%\n",
            "Chunk 8: Detected Class = gun_shot, Confidence = 94.98%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 9: Detected Class = gun_shot, Confidence = 98.29%\n",
            "Chunk 10: Detected Class = dog_bark, Confidence = 69.88%\n",
            "Chunk 11: Detected Class = gun_shot, Confidence = 61.14%\n",
            "Chunk 12: Detected Class = dog_bark, Confidence = 70.94%\n",
            "Chunk 13: Detected Class = street_music, Confidence = 92.30%\n",
            "Chunk 14: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 15: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 16: Detected Class = gun_shot, Confidence = 100.00%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 17: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 18: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 19: Detected Class = gun_shot, Confidence = 99.99%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 20: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 21: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 22: Detected Class = gun_shot, Confidence = 99.93%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 23: Detected Class = gun_shot, Confidence = 93.06%\n",
            "Chunk 24: Detected Class = gun_shot, Confidence = 99.57%\n",
            "Chunk 25: Detected Class = dog_bark, Confidence = 53.49%\n",
            "Chunk 26: Detected Class = gun_shot, Confidence = 99.47%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 27: Detected Class = gun_shot, Confidence = 91.42%\n",
            "Chunk 28: Detected Class = gun_shot, Confidence = 99.84%\n",
            "Chunk 29: Detected Class = dog_bark, Confidence = 64.08%\n",
            "Chunk 30: Detected Class = gun_shot, Confidence = 70.45%\n",
            "Chunk 31: Detected Class = dog_bark, Confidence = 98.24%\n",
            "Chunk 32: Detected Class = gun_shot, Confidence = 99.47%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 33: Detected Class = gun_shot, Confidence = 97.94%\n",
            "Chunk 34: Detected Class = gun_shot, Confidence = 94.40%\n",
            "Chunk 35: Detected Class = gun_shot, Confidence = 99.74%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 36: Detected Class = gun_shot, Confidence = 92.59%\n",
            "Chunk 37: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 38: Detected Class = dog_bark, Confidence = 99.82%\n",
            "Chunk 39: Detected Class = street_music, Confidence = 89.38%\n",
            "Chunk 40: Detected Class = dog_bark, Confidence = 47.44%\n",
            "Chunk 41: Detected Class = dog_bark, Confidence = 81.77%\n",
            "Chunk 42: Detected Class = street_music, Confidence = 41.61%\n",
            "Chunk 43: Detected Class = street_music, Confidence = 95.13%\n",
            "Chunk 44: Detected Class = street_music, Confidence = 96.71%\n",
            "Chunk 45: Detected Class = street_music, Confidence = 56.49%\n",
            "Chunk 46: Detected Class = gun_shot, Confidence = 99.83%\n",
            "Chunk 47: Detected Class = gun_shot, Confidence = 99.58%\n",
            "Chunk 48: Detected Class = street_music, Confidence = 72.32%\n",
            "Chunk 49: Detected Class = dog_bark, Confidence = 59.06%\n",
            "Chunk 50: Detected Class = street_music, Confidence = 60.04%\n",
            "Chunk 51: Detected Class = gun_shot, Confidence = 93.74%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 52: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 53: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 54: Detected Class = gun_shot, Confidence = 99.44%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 55: Detected Class = gun_shot, Confidence = 99.97%\n",
            "Chunk 56: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 57: Detected Class = gun_shot, Confidence = 99.98%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Failed to send email: (250, b'2.0.0 OK  1730064653 af79cd13be357-7b18d27a47asm265023385a.25 - gsmtp')\n",
            "Chunk 58: Detected Class = gun_shot, Confidence = 99.99%\n",
            "Chunk 59: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 60: Detected Class = gun_shot, Confidence = 99.99%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 61: Detected Class = gun_shot, Confidence = 99.89%\n",
            "Chunk 62: Detected Class = gun_shot, Confidence = 99.95%\n",
            "Chunk 63: Detected Class = drilling, Confidence = 93.88%\n",
            "Chunk 64: Detected Class = gun_shot, Confidence = 99.73%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 65: Detected Class = drilling, Confidence = 66.32%\n",
            "Chunk 66: Detected Class = gun_shot, Confidence = 94.57%\n",
            "Chunk 67: Detected Class = gun_shot, Confidence = 97.59%\n",
            "Chunk 68: Detected Class = gun_shot, Confidence = 99.68%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 69: Detected Class = gun_shot, Confidence = 99.73%\n",
            "Chunk 70: Detected Class = gun_shot, Confidence = 96.16%\n",
            "Chunk 71: Detected Class = drilling, Confidence = 56.81%\n",
            "Chunk 72: Detected Class = gun_shot, Confidence = 97.59%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 73: Detected Class = dog_bark, Confidence = 68.58%\n",
            "Chunk 74: Detected Class = gun_shot, Confidence = 99.82%\n",
            "Chunk 75: Detected Class = gun_shot, Confidence = 100.00%\n",
            "Chunk 76: Detected Class = gun_shot, Confidence = 99.94%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Email alert sent successfully!\n",
            "Chunk 77: Detected Class = drilling, Confidence = 98.86%\n",
            "Chunk 78: Detected Class = gun_shot, Confidence = 99.98%\n",
            "Chunk 79: Detected Class = gun_shot, Confidence = 99.97%\n",
            "Chunk 80: Detected Class = gun_shot, Confidence = 35.27%\n",
            "Chunk 81: Detected Class = gun_shot, Confidence = 99.48%\n",
            "3 gunshots detected within the last 6 chunks. Sending email alert...\n",
            "Failed to send email: (250, b'2.0.0 OK  1730064666 d75a77b69052e-4613237456esm28563081cf.77 - gsmtp')\n",
            "Chunk 82: Detected Class = gun_shot, Confidence = 97.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGkpqqX1oCpd"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}